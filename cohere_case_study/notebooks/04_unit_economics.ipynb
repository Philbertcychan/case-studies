{"cells": [{"cell_type": "markdown", "metadata": {}, "source": "# \ud83d\udcb0 Unit Economics of Token Inference\n\nThis notebook models the unit economics of Cohere's API usage, simulating revenue, cost, and gross margin per million tokens."}, {"cell_type": "markdown", "metadata": {}, "source": "## \ud83e\uddfe Defining the Unit\n\nWe define **1 unit** as processing **1 million tokens** through Cohere\u2019s model API. This is the core economic driver."}, {"cell_type": "markdown", "metadata": {}, "source": "## \ud83d\udcc8 Revenue Per Unit\n\nUsing hypothetical pricing from our tiering model:\n\n| Tier       | Price per 1M Tokens (USD) |\n|------------|----------------------------|\n| Starter    | $2.00                     |\n| Growth     | $1.75                     |\n| Pro        | $1.50                     |\n| Enterprise | $1.20                     |"}, {"cell_type": "markdown", "metadata": {}, "source": "## \u2699\ufe0f Cost Estimation per Unit\n\nModel inference cost depends on hardware, model size, and latency.\n\n- Assume GPU cost: **$2.50/hour** (A100 spot pricing on AWS)\n- Tokens/sec per GPU for a GPT-like model: **40 tokens/sec**\n- Cost per 1M tokens = `($2.50 / 3600) * (1,000,000 / 40)` = ~$17.36\n\n(Real world optimizations + batching can reduce this significantly.)\n\nLet\u2019s simulate costs under different scenarios."}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "import pandas as pd\n\n# Revenue and Cost Simulation\npricing_per_million = {\n    \"Starter\": 2.00,\n    \"Growth\": 1.75,\n    \"Pro\": 1.50,\n    \"Enterprise\": 1.20\n}\n\ncost_scenarios = {\n    \"Baseline\": 17.36,\n    \"Optimized\": 8.50,\n    \"Heavily Optimized\": 3.00\n}\n\nrows = []\nfor tier, price in pricing_per_million.items():\n    for cost_label, cost_val in cost_scenarios.items():\n        margin = price - cost_val\n        rows.append({\n            \"Tier\": tier,\n            \"Price\": price,\n            \"Cost Scenario\": cost_label,\n            \"Cost\": cost_val,\n            \"Margin\": margin\n        })\n\ndf = pd.DataFrame(rows)\ndf"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "import seaborn as sns\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(10, 6))\nsns.barplot(data=df, x=\"Tier\", y=\"Margin\", hue=\"Cost Scenario\", palette=\"coolwarm\")\nplt.axhline(0, color='black', linestyle='--')\nplt.title(\"Gross Margin per 1M Tokens by Tier and Cost Scenario\")\nplt.ylabel(\"Gross Margin (USD)\")\nplt.xlabel(\"Tier\")\nplt.tight_layout()\nplt.savefig('../report/graphics/unit_margin_sim.png')\nplt.show()"}, {"cell_type": "markdown", "metadata": {}, "source": "## \ud83d\udcca Summary of Insights\n\n- **High cloud GPU costs** crush margins at low price points unless throughput is extremely optimized.\n- **Starter and Growth tiers** are loss leaders unless costs are reduced dramatically.\n- **Enterprise clients** offer much more margin flexibility due to contract pricing and volume guarantees.\n\nKey takeaway: **scaling margin depends more on cost structure than pricing.**"}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.x"}}, "nbformat": 4, "nbformat_minor": 2}